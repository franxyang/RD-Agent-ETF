# ==========================================
# RD-Agent 完整环境变量配置模板
# 版本: 1.0.0 | 更新日期: 2025-08-08
# ==========================================
# 
# 使用说明:
# 1. 复制此文件为 .env 并根据实际需求配置
# 2. 所有配置项都有默认值，仅需修改必要项
# 3. 敏感信息(API Keys等)使用前必须替换
# 4. 支持的配置前缀按功能模块划分
#
# ==========================================


# ==========================================
# 一、核心配置 (Core Settings)
# ==========================================

# === 1.1 全局配置 ===
# 最大重试次数 (默认: 10)
MAX_RETRY=10

# 重试等待时间(秒) (默认: 20)
RETRY_WAIT_SECONDS=20

# 工作空间路径 (默认: ./git_ignore_folder/RD-Agent_workspace)
# WORKSPACE_PATH=/path/to/workspace

# 多进程数量 (默认: 1)
# MULTI_PROC_N=1

# 并行步骤信号量 (默认: 1, 可设置为字典如 {"coding": 3, "running": 2})
# STEP_SEMAPHORE=1

# 标准输出上下文长度限制 (默认: 400)
# STDOUT_CONTEXT_LEN=400

# 标准输出行长度限制 (默认: 10000)
# STDOUT_LINE_LEN=10000

# 启用MLflow追踪 (默认: False)
# ENABLE_MLFLOW=False

# 初始因子库大小 (默认: 20)
# INITIAL_FATOR_LIBRARY_SIZE=20

# === 1.2 缓存配置 ===
# 启用pickle缓存 (默认: True)
# CACHE_WITH_PICKLE=True

# pickle缓存文件夹路径 (默认: ./pickle_cache/)
# PICKLE_CACHE_FOLDER_PATH_STR=/path/to/pickle_cache

# 使用文件锁避免重复执行 (默认: True)
# USE_FILE_LOCK=True

# 启用聊天缓存 (默认: False)
USE_CHAT_CACHE=False

# 启用嵌入缓存 (默认: False)
USE_EMBEDDING_CACHE=False

# 提示缓存数据库路径 (默认: ./prompt_cache.db)
# PROMPT_CACHE_PATH=/path/to/prompt_cache.db

# 自动生成聊天缓存种子 (默认: False)
# USE_AUTO_CHAT_CACHE_SEED_GEN=False

# 初始聊天缓存种子 (默认: 42)
# INIT_CHAT_CACHE_SEED=42


# ==========================================
# 二、LLM后端配置 (Backend Configuration)
# ==========================================

# === 2.1 后端选择 ===
# 后端实现类 (默认: rdagent.oai.backend.LiteLLMAPIBackend)
BACKEND=rdagent.oai.backend.LiteLLMAPIBackend

# === 2.2 模型配置 ===
# 聊天模型 (支持: gpt-4o, deepseek-chat, o3-mini等)
CHAT_MODEL="o3-mini"

# 嵌入模型 (支持: text-embedding-3-small, BAAI/bge-m3等)
EMBEDDING_MODEL="text-embedding-3-small"

# 推理努力程度 (仅o3系列, 可选: low, medium, high)
# REASONING_EFFORT=medium

# 启用函数调用 (默认: True, 部分模型不支持)
# ENABLE_FUNCTION_CALL=True

# === 2.3 OpenAI配置 ===
# OpenAI API基础URL
OPENAI_API_BASE="https://api.openai.com/v1"

# OpenAI API密钥 (必须替换为实际密钥)
OPENAI_API_KEY="sk-your-actual-api-key-here"

# 聊天专用API密钥 (可选，不设置则使用OPENAI_API_KEY)
# CHAT_OPENAI_API_KEY="sk-chat-specific-key"

# 聊天专用基础URL (可选)
# CHAT_OPENAI_BASE_URL="https://custom-endpoint.com/v1"

# === 2.4 生成参数配置 ===
# 温度参数 (0.0-2.0, 默认: 0.5, 越高越随机)
CHAT_TEMPERATURE=1.0

# 最大token数 (默认: None, 自动)
# CHAT_MAX_TOKENS=4096

# 流式输出 (默认: True)
# CHAT_STREAM=True

# 随机种子 (默认: None, 用于可重现结果)
# CHAT_SEED=42

# 频率惩罚 (默认: 0.0)
# CHAT_FREQUENCY_PENALTY=0.0

# 存在惩罚 (默认: 0.0)
# CHAT_PRESENCE_PENALTY=0.0

# Token限制 (默认: 100000)
# CHAT_TOKEN_LIMIT=100000

# === 2.5 推理处理配置 ===
# 移除<think>标签内容 (o3系列模型需要, 默认: False)
REASONING_THINK_RM=True

# 系统提示词角色 (默认: system, o1模型使用user)
# SYSTEM_PROMPT_ROLE=system

# 默认系统提示词
# DEFAULT_SYSTEM_PROMPT="You are an AI assistant who helps to answer user's questions."

# === 2.6 Azure配置 (可选) ===
# 使用Azure聊天服务
# CHAT_USE_AZURE=True

# Azure聊天API基础URL
# CHAT_AZURE_API_BASE="https://your-resource.openai.azure.com/"

# Azure聊天API版本
# CHAT_AZURE_API_VERSION="2024-02-15-preview"

# 使用Azure嵌入服务
# EMBEDDING_USE_AZURE=True

# Azure嵌入API基础URL
# EMBEDDING_AZURE_API_BASE="https://your-resource.openai.azure.com/"

# Azure嵌入API版本
# EMBEDDING_AZURE_API_VERSION="2024-02-15-preview"

# === 2.7 其他LLM服务配置 ===
# DeepSeek配置示例
# CHAT_MODEL=deepseek/deepseek-chat
# DEEPSEEK_API_KEY=sk-your-deepseek-key

# SiliconFlow嵌入配置示例
# EMBEDDING_MODEL=litellm_proxy/BAAI/bge-m3
# LITELLM_PROXY_API_KEY=sk-your-siliconflow-key
# LITELLM_PROXY_API_BASE=https://api.siliconflow.cn/v1

# === 2.8 本地LLaMA配置 (可选) ===
# 使用本地LLaMA2
# USE_LLAMA2=True

# LLaMA2检查点目录
# LLAMA2_CKPT_DIR=Llama-2-7b-chat

# LLaMA2分词器路径
# LLAMA2_TOKENIZER_PATH=Llama-2-7b-chat/tokenizer.model

# LLaMA2最大批处理大小
# LLAMS2_MAX_BATCH_SIZE=8


# ==========================================
# 三、因子挖掘配置 (Factor Mining)
# ==========================================

# === 3.1 Factor CoSTEER配置 ===
# 主数据源路径 (HDF5格式，用于因子生成)
FACTOR_CoSTEER_data_folder=/Users/handsomedoge/Documents/CITIC_quant/qlib_etf_data_h5

# 调试数据源路径
FACTOR_CoSTEER_data_folder_debug=/Users/handsomedoge/Documents/CITIC_quant/qlib_etf_data_h5

# Python二进制路径 (默认: python)
# FACTOR_CoSTEER_python_bin=/usr/bin/python3

# 因子执行超时时间(秒) (默认: 3600)
FACTOR_CoSTEER_file_based_execution_timeout=3600

# 因子选择方法 (random/greedy/adaptive)
FACTOR_CoSTEER_select_method=random

# 因子生成温度 (0.0-2.0, 控制多样性)
FACTOR_CoSTEER_temperature=0.9

# 因子变异率 (0.0-1.0)
FACTOR_CoSTEER_mutation_rate=0.5

# 使用简单背景信息 (默认: False)
# FACTOR_CoSTEER_simple_background=False

# === 3.2 因子提取配置 ===
# 最大输入重复因子组数 (默认: 300)
# MAX_INPUT_DUPLICATE_FACTOR_GROUP=300

# 最大输出重复因子组数 (默认: 20)
# MAX_OUTPUT_DUPLICATE_FACTOR_GROUP=20

# 最大KMeans分组数 (默认: 40)
# MAX_KMEANS_GROUP_NUMBER=40


# ==========================================
# 四、模型训练配置 (Model Training)
# ==========================================

# === 4.1 Model CoSTEER配置 ===
# 数据文件夹路径
# MODEL_CoSTEER_data_folder=/path/to/model_data

# 调试数据文件夹路径
# MODEL_CoSTEER_data_folder_debug=/path/to/model_data_debug

# Python二进制路径
# MODEL_CoSTEER_python_bin=python

# 模型执行超时时间(秒)
# MODEL_CoSTEER_file_based_execution_timeout=7200

# 模型选择方法
# MODEL_CoSTEER_select_method=adaptive


# ==========================================
# 五、Qlib相关配置 (Qlib Settings)
# ==========================================

# === 5.1 Qlib因子配置 ===
# 因子生成器名称
# QLIB_FACTOR_FACTOR_GENERATOR_NAME=FactorGenerator

# 因子评估器名称
# QLIB_FACTOR_FACTOR_EVALUATOR_NAME=FactorEvaluator

# 因子实现类型
# QLIB_FACTOR_FACTOR_IMPLEMENTATION_TYPE=PandasImplementation

# 因子评估回测
# QLIB_FACTOR_FACTOR_EVAL_BACKTEST=True

# 因子最小长度
# QLIB_FACTOR_FACTOR_MIN_LEN=10

# 因子最大长度
# QLIB_FACTOR_FACTOR_MAX_LEN=100

# === 5.2 Qlib模型配置 ===
# 模型实现类型
# QLIB_MODEL_MODEL_IMPLEMENTATION_TYPE=PyTorchImplementation

# 模型评估器名称
# QLIB_MODEL_MODEL_EVALUATOR_NAME=ModelEvaluator

# 模型评估回测
# QLIB_MODEL_MODEL_EVAL_BACKTEST=True

# === 5.3 Qlib Docker配置 ===
# 从Dockerfile构建 (默认: True)
# QLIB_DOCKER_BUILD_FROM_DOCKERFILE=True

# Dockerfile文件夹路径
# QLIB_DOCKER_DOCKERFILE_FOLDER_PATH=/path/to/dockerfile

# Docker镜像名称
# QLIB_DOCKER_IMAGE=local_qlib:latest

# 容器挂载路径
# QLIB_DOCKER_MOUNT_PATH=/workspace/qlib_workspace/

# 默认入口命令
# QLIB_DOCKER_DEFAULT_ENTRY="qrun conf.yaml"

# 共享内存大小
# QLIB_DOCKER_SHM_SIZE=16g

# 启用GPU (默认: True)
# QLIB_DOCKER_ENABLE_GPU=True

# 启用缓存 (默认: False)
# QLIB_DOCKER_ENABLE_CACHE=False

# 运行超时时间(秒) (默认: 300)
# QLIB_DOCKER_RUNNING_TIMEOUT_PERIOD=300

# 内存限制
# QLIB_DOCKER_MEM_LIMIT=32g


# ==========================================
# 六、数据科学配置 (Data Science)
# ==========================================

# === 6.1 DS Coder CoSTEER配置 ===
# 数据文件夹路径
# DS_Coder_CoSTEER_data_folder=/path/to/ds_data

# 调试数据文件夹路径
# DS_Coder_CoSTEER_data_folder_debug=/path/to/ds_data_debug

# 执行超时时间(秒)
# DS_Coder_CoSTEER_file_based_execution_timeout=3600

# === 6.2 DS Docker配置 ===
# Docker镜像
# DS_DOCKER_IMAGE=gcr.io/kaggle-gpu-images/python:latest

# 挂载路径
# DS_DOCKER_MOUNT_PATH=/kaggle/workspace

# 默认入口
# DS_DOCKER_DEFAULT_ENTRY="python main.py"

# 运行超时时间(秒)
# DS_DOCKER_RUNNING_TIMEOUT_PERIOD=600

# 内存限制
# DS_DOCKER_MEM_LIMIT=48g


# ==========================================
# 七、Kaggle配置 (Kaggle Competition)
# ==========================================

# === 7.1 KG基础配置 ===
# Kaggle用户名
# KG_USERNAME=your_kaggle_username

# Kaggle API密钥
# KG_API_KEY=your_kaggle_api_key

# === 7.2 KG Docker配置 ===
# 从Dockerfile构建
# KG_DOCKER_BUILD_FROM_DOCKERFILE=True

# Docker镜像
# KG_DOCKER_IMAGE=local_kg:latest

# 挂载路径
# KG_DOCKER_MOUNT_PATH=/workspace/kg_workspace/

# 默认入口
# KG_DOCKER_DEFAULT_ENTRY="python train.py"

# 运行超时时间(秒)
# KG_DOCKER_RUNNING_TIMEOUT_PERIOD=600

# 内存限制
# KG_DOCKER_MEM_LIMIT=48g


# ==========================================
# 八、MLE-Bench配置 (MLE Benchmark)
# ==========================================

# === 8.1 MLEB Docker配置 ===
# 从Dockerfile构建
# MLEB_DOCKER_BUILD_FROM_DOCKERFILE=True

# Dockerfile文件夹路径
# MLEB_DOCKER_DOCKERFILE_FOLDER_PATH=/path/to/mle_bench_docker

# Docker镜像
# MLEB_DOCKER_IMAGE=local_mle:latest

# 挂载路径
# MLEB_DOCKER_MOUNT_PATH=/workspace/mleb_workspace/

# 运行超时时间(秒)
# MLEB_DOCKER_RUNNING_TIMEOUT_PERIOD=1200

# 内存限制
# MLEB_DOCKER_MEM_LIMIT=32g


# ==========================================
# 九、基准测试配置 (Benchmark)
# ==========================================

# 基准测试数据路径
# BENCHMARK_DATA_PATH=/path/to/benchmark_data

# 基准测试结果路径
# BENCHMARK_RESULT_PATH=/path/to/benchmark_results

# 基准测试超时时间(秒)
# BENCHMARK_TIMEOUT=3600


# ==========================================
# 十、日志配置 (Logging)
# ==========================================

# 日志级别 (DEBUG/INFO/WARNING/ERROR/CRITICAL)
# LOG_LEVEL=INFO

# 日志格式
# LOG_FORMAT="%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# 日志文件路径
# LOG_FILE_PATH=/path/to/rdagent.log

# 日志文件最大大小(MB)
# LOG_MAX_FILE_SIZE=100

# 日志文件备份数量
# LOG_BACKUP_COUNT=5

# 记录LLM聊天内容 (默认: True)
# LOG_LLM_CHAT_CONTENT=True

# 转储聊天缓存 (默认: False)
# DUMP_CHAT_CACHE=False

# 转储嵌入缓存 (默认: False)
# DUMP_EMBEDDING_CACHE=False


# ==========================================
# 十一、UI配置 (User Interface)
# ==========================================

# UI服务器主机
# UI_HOST=0.0.0.0

# UI服务器端口
# UI_PORT=8080

# UI静态文件路径
# UI_STATIC_PATH=/path/to/static

# UI模板路径
# UI_TEMPLATE_PATH=/path/to/templates


# ==========================================
# 十二、文档智能配置 (Document Intelligence)
# ==========================================

# Azure文档智能密钥
# AZURE_DOCUMENT_INTELLIGENCE_KEY=your_key

# Azure文档智能端点
# AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=https://your-resource.cognitiveservices.azure.com/


# ==========================================
# 十三、高级配置 (Advanced Settings)
# ==========================================

# === 13.1 性能优化 ===
# 最大过去消息包含数 (默认: 10)
# MAX_PAST_MESSAGE_INCLUDE=10

# 超时失败限制 (默认: 10)
# TIMEOUT_FAIL_LIMIT=10

# 违规失败限制 (默认: 1)
# VIOLATION_FAIL_LIMIT=1

# 嵌入最大字符串数 (默认: 50)
# EMBEDDING_MAX_STR_NUM=50

# === 13.2 调试配置 ===
# 强制子进程步骤 (默认: False)
# SUBPROC_STEP=False

# === 13.3 实验性功能 ===
# 启用实验性功能 (默认: False)
# ENABLE_EXPERIMENTAL_FEATURES=False


# ==========================================
# 注意事项
# ==========================================
# 1. API密钥必须替换为实际值，绝不要提交到版本控制
# 2. 路径配置建议使用绝对路径
# 3. Docker相关配置需要Docker环境正常运行
# 4. 内存和超时配置根据实际硬件调整
# 5. 生产环境建议关闭调试和缓存转储功能
# 6. 多进程配置需要充足的系统资源
# 7. 日志级别生产环境建议使用INFO或WARNING
# 8. 温度参数影响生成多样性，研究阶段可适当提高
# 9. 所有配置都有默认值，仅需修改必要项
# 10. 配置优先级: 环境变量 > .env文件 > 默认值